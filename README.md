# Задача 3 
> Дан видеопоток, записанный с фронтальной камеры автомобиля. Задача: обнаружить и распознать все знаки, попавшие в поле зрения камеры. Как вы будете решать эту задачу, какие инструменты будете использовать? 

Может быть множество подходов к решению этой задачи и только эксперимент им судья. 

> "Все модели неправильные, но некоторые из них полезные." — Джорж Бокс 

Здесь описан вариант, который кажется логичным мне. 
Задачу разбиваем на несколько подзадач: 

- Нахождение дорожных знаков на изображении (**bounding box detection**). 
- Классификация дорожных знаков по изображениям полученным из **bounding box**'ов.  
- *Дополнительно*. Отслеживание (**tracking**) дорожных знаков между фреймами (**tracking** все равно придется делать, т.к. знать положение некоторых знаков относительно дороги, необходимо для принятия решений агента/водителя). 

### Нахождение дорожных знаков на изображении 
Существует множество решений на основе скользящего окна (**sliding window**), и атрибутов (features), таких как **HOG**, верхние сверточные слои сетей с **ImageNet** (имеется ввиду убрать верхние полносвязные слои для классификации, и использовать оставшиеся верхний сверточный слой как высокоуровневые атрибуты для другой задачи). Но большинство из них будет страдать на изображениях с большим числом детектируемых объектов. И определенно, дорожные знаки будут доставлять подобные трудности: ![multi_signs](https://github.com/rb-kuddai/yd_drone/blob/master/img/traffic_signs_multi.jpg) 

Скользящие окна, либо приведут к большему количеству false-positive, либо часть знаков будет теряться при **non-maxima suppression**, или схожих подходах. 

Есть очень интересная статья позволяющая адресовать эту проблему [1](https://arxiv.org/pdf/1506.04878.pdf) (спасибо [2](http://cv-blog.ru/?p=72) за доступное объяснение). В ней рассматривается задача детектирования человеческих лиц/голов в толпе. 

Ключевые идеи: 

 - Используется **GoogLeNet** предобученный на ImageNet в качестве
   высокоуровневых атрибутов
 - **LSTM** используются, чтобы генерировать bounding box'ы, с дополнительным параметром определяющим насколько вероятно что искомое изображение (в их случае лицо) попало в bounding box. Образцы из LSTM генерируются в порядке убывания вероятности нахождения искомого изображения. Как только вероятность падает ниже заранее определенного значения генерация прекращается. Это позволяет легко получать bounding box для множества объектов на картинке (в том числе тесно стоящих друг к другу или частично перекрывающихся). Архитектура выглядит как <br />![end-to-end-structure](https://github.com/rb-kuddai/yd_drone/blob/master/img/end-to-end-structure.png) 
 - Используется специальная функция потерь на основе венгерского алгоритма, состоящая из двух частей <br /> ![loss](https://github.com/rb-kuddai/yd_drone/blob/master/img/loss_function.png) <br /> Первая часть заставляет алгоритм выбирать bounding box наиболее близкий к целевому, вторая часть - штраф за ложный bounding box. Это позволяет алгоритму работать верно в ситуациях с множеством объектов (результат работы алгоритма на картинке (с)): <br /> ![result](https://github.com/rb-kuddai/yd_drone/blob/master/img/result.png) <br /> 

На выходе у нас есть bounding box'ы данные, часть из которых нужно классифицировать вручную, чтобы иметь данные для классификации знаков (другую часть можно использовать для **semi-supervised learning**, об этом далее). 

### Классификация дорожных знаков по изображениям 
Задача классификации со множеством классов (чаще всего ставим **softmax** на конец сети). Используем архитектуры, предобученные на ImageNet, (например опять тот же GoogLeNet). Судя по анализу схожего с задачей **German Traffic sign dataset** взятого из [3](https://hackernoon.com/traffic-signs-classification-with-deep-learning-b0cb03e23efb#.i7nii4t8k) 

![imbalance_classes](https://github.com/rb-kuddai/yd_drone/blob/master/img/imbalance.png) 

классы не будут распространены одинаково, поэтому можно сбалансировать их посредством аугментации данных (трансляции, вращения, цветовой коррекции) и/или подкручивая веса у функции потерь. 

Также на этом шаге желательно убрать знаки, которые не оказывают влияния на решения принимаемые агентом в один класс (назвать его useless/other), чтобы увеличить количество примеров приходящиеся на каждый класс. По такому же принципу, нужно объединить классы, которые приводят к одним и тем же действиям агента (например, "риск обвала", или "осторожно звери", оба могут приводить к более аккуратной езде ). 

Из интересных идей. Т.к. можно собрать гораздо больше неподкрепленных данных, чем подкрепленных, то можно попробовать архитектуру типа **LadderNetwork** [4](https://arxiv.org/pdf/1507.02672.pdf) для semi-supervised learning, которая могла бы утилизировать неподкрепленные данные. Но она накладывает некоторые ограничения на supervised часть сети, так что скорее всего это не даст выигрыша, но попробовать можно. 

### Tracking 
Здесь несколько, сложно сказать, т.к. это этап стоит связывать не только с результатами предыдущих этапов, но и с другими сенсорами агента (и командами подданными на исполнение агенту/водителю) через **SLAM**. Можно применить **Bayesian Networks**, чтобы отслеживать наиболее вероятные гипотезы для разных дорожных знаков (например, тот же этот самый знак, что и в предыдущем кадре, пропал ли он времено из-за заперекрытия, и т.д.). На выходе, желательно получить несколько кадров для каждого знака, что может помочь улучшить точность классификации (использовать majority voting, или геометрическое среднее вероятностей). Это должно в теории помочь определять дорожные знаки, которые были записанны на большой скорости.

### Примечания 
Лучше всего обучить несколько версий приведенных выше систем в зависимости от времени суток и сезона (зимой распределение цветов сильно другое, плюс знаки могут быть частично закрыты снегом). Классификация знаков в темноте (ночь, закрытая парковка, туннель) будет работать иначе чем днем, и предобучение на ImageNet меньше поможет, т.к. там большинство классов день. Поэтому лучше выделить отдельную подсистему, которая будет определять текущую среду (например, разделить время суток по интенсивности: день, рассвет/сумерки, ночь). 

### Ссылки 
[1 End-to-end people detection in crowded scenes](https://arxiv.org/pdf/1506.04878.pdf) 

[2 Функция потерь в обучении](http://cv-blog.ru/?p=72) 

[3 Traffic signs classification with Deep Learning](https://hackernoon.com/traffic-signs-classification-with-deep-learning-b0cb03e23efb#.i7nii4t8k) 

[4 Semi-Supervised Learning with Ladder Networks](https://arxiv.org/pdf/1507.02672.pdf) 

# Задача 1 
> Что такое регуляризация и как она применяется в машинном обучении? Из каких соображений выбирают методы регуляризации в практических задачах? 

Регуляризация призвана бороться с переобучением в машинном обучении. Т.е. позволяет избегать ситуаций, когда мы начинаем учить шум или неважные особенности тренировочного сэта, вместо того чтобы схватывать общий паттерн. Другие определения. Предотвращение уменьшения функции потерь на тренировочных данных, при ее увеличении на тестовых. Регуляризация зачастую приводит к уменьшению variance error, за счет увеличения bias error. 

Часто регуляризация, это наш способ заложить в систему приорные знания, Например, регуляризация для линейной ригрессии, это по сути наложение гауссного приора на линейные веса, что приводит к тому что система будет отдавать предпочтение моделям с меньшими абсолютными значениями весов. Поэтому метод регуляризации стоит выбирать в зависимости от тех приорных знаний, которые мы считаем верными. 

Для нейронных сетей, R1 и R2 регуляризации дают пенальти за слишком большие веса (очень большие веса при прочих равных ведут к неустойчивости системы). R1 регуляризация подходит для слоев, где активационная функция ограничена с двух концов (sigmoid, tanh). R2 подходит для активационных слоев, где этого ограничения нет (relu). Также для регуляризации можно использовать Dropout, чтобы система слишком сильно не полагалась на ограниченный набор нейронов, это помогает в системах, где в слоях много нейронов. Batch normalization, также оказывает эффект регуляризации (полезно в глубоких сетях). 

# Задача 2
> 	Рассмотрим контейнеры из C++ STL. В каких из них можно организовать поиск элемента за O(log(n)) и почему?
std::vector
std::list
std::deque
std::set
std::unordered_set
Можно ли организовать поиск элемента за O(log(n)) в этих контейнерах, если предварительно их отсортировать?

* std::vector. Можно получить доступ к элементу за константное время. Внутри сделан из динамически расширяющегося массива. Поэтому поиск за O(log(n)) в общем случае невозможен. Если предварительно отсортирован, то  O(log(n)) возможен с помощью бинарного поиска.
* std::list. Нельзя получить доступ к элементу за константное время. Сделан с помощью двухсвязного списка. Поэтому O(log(n))  невозможен, как в случае неотсортированного списка, так и отсортированного.
* std::deque. Можно получить доступ к элементу за константное время. Поэтому поиск за O(log(n)) в общем случае невозможен. Если предварительно отсортирован, то  O(log(n)) возможен с помощью бинарного поиска.
* std::set. Обычно реализация через одно из сбалансированных деревьев, поэтому возможен поиск за O(log(n))
* std::unordered_set. Является hashmap'ом внутри, поэтому поиск элемента происходит за константное время O(1). Нельзя отсортировать.

